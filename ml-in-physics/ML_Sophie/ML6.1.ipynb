{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "\n",
    "doing classification on every pixel, so the input and output share the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 5.1 \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "# imports our layers we want to use\n",
    "\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy #loss function\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD #optimisers\n",
    "from tensorflow.keras.utils import to_categorical #some function for data preparation\n",
    "\n",
    "from tensorflow.compat.v1 import disable_eager_execution\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 568, 568, 64)\n",
      "(None, 196, 196, 64)\n",
      "(None, 6, 6, 512)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 0 for 'max_pooling2d_93/MaxPool' (op: 'MaxPool') with input shapes: [?,0,0,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1618\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1619\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 0 for 'max_pooling2d_93/MaxPool' (op: 'MaxPool') with input shapes: [?,0,0,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-bb29bc18f7c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mconv4\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mCropping2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mpool4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mpool4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    772\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   3873\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3874\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3875\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   3876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5198\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m   5199\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5200\u001b[1;33m                    data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5201\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5202\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1786\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1621\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 0 for 'max_pooling2d_93/MaxPool' (op: 'MaxPool') with input shapes: [?,0,0,512]."
     ]
    }
   ],
   "source": [
    "# build model\n",
    "\n",
    "init = tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None)\n",
    "\n",
    "# 4 blocks in contracting path\n",
    "\n",
    "# want to use padding \"valid\" because the convolutions have to be unpadded\n",
    "f = 64\n",
    "input_layer = Input((572, 572, 1))\n",
    "\n",
    "# it is necessary to give a name to our layer outputs because we want to use them later in the upscaling again \n",
    "# conv1 = model.add(Conv2D(f, (3,3), padding=\"valid\", strides=1, activation=\"relu\", input_shape=(572,572,1)))\n",
    "# conv1 = model.add(Conv2D(f, (3,3), padding=\"valid\", strides=1, activation=\"relu\"))(conv1)\n",
    "# pool1= model.add(MaxPooling2D(pool_size=(2,2)))(conv1)\n",
    "# pool1 = model.add(Dropout(0.25))(pool1)\n",
    "\n",
    "#1\n",
    "conv1 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=init)(input_layer)\n",
    "conv1 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=init)(conv1)\n",
    "\n",
    "print(np.shape(conv1))\n",
    "conv1 = Cropping2D(cropping=((88, 88), (88, 88)))(conv1)\n",
    "pool1= MaxPooling2D((2,2))(conv1)\n",
    "pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "print(np.shape(pool1))\n",
    "\n",
    "#2\n",
    "conv2 = Conv2D(2*f, (3,3), activation=\"relu\", kernel_initializer=init)(pool1)\n",
    "conv2 = Conv2D(2*f, (3,3), strides=1, activation=\"relu\", kernel_initializer=init)(conv2)\n",
    "conv2  = Cropping2D(cropping=((40, 40), (40, 40)))(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "#3\n",
    "conv3 = Conv2D(4*f, (3,3), activation=\"relu\", kernel_initializer=init)(pool2)\n",
    "conv3 = Conv2D(4*f, (3,3), activation=\"relu\", kernel_initializer=init)(conv3)\n",
    "conv3  = Cropping2D(cropping=((16, 16), (16, 16)))(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "pool3 = Dropout(0.25)(pool3)\n",
    "\n",
    "#4\n",
    "conv4 = Conv2D(8*f, (3,3), activation=\"relu\", kernel_initializer=init)(pool3)\n",
    "conv4 = Conv2D(8*f, (3,3), activation=\"relu\", kernel_initializer=init)(conv4)\n",
    "print(np.shape(conv4))\n",
    "conv4  = Cropping2D(cropping=((4, 4), (4, 4)))(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "pool4 = Dropout(0.25)(pool4)\n",
    "\n",
    "# middle/ bottom part: \n",
    "conv_m = Conv2D(16*f, (3,3), padding=\"valid\", activation=\"relu\", kernel_initializer=init)(pool4)\n",
    "conv_m = Conv2D(16*f, (3,3), padding=\"valid\", activation=\"relu\", kernel_initializer=init)(conv_m)\n",
    "\n",
    "# expansive part\n",
    "\n",
    "# we want to upsize the image back to it's original size\n",
    "# use transposed convolution for this \n",
    "# trasposed convolution =/= deconvolution\n",
    "# transposed convolution is somewhat similar\n",
    "# it produces the same spatial resolution a hypothetical deconvolutional layer would\n",
    "# only thing in common is it guarantees that the output will be a 5x5 image as well\n",
    "# back to original shape \n",
    "# this step will not reverse the process from above. At least not concerning the numeric values.\n",
    "\n",
    "# concatenate: It takes as input a list of tensors, all of the same shape except for the concatenation axis\n",
    "# and returns a single tensor that is the concatenation of all inputs.\n",
    "# Concatenate = verknüpfen \n",
    "\n",
    "deconv4 = Conv2DTranspose(f*8, (2,2), strides=(2,2), padding=\"same\", kernel_initializer=init)(conv_m)\n",
    "uconv4 = concatenate([deconv4,conv4])\n",
    "uconv4 = Conv2D(f*8, (3,3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "uconv4 = Conv2D(f*8, (3,3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "deconv3 = Conv2DTranspose(f*4, (2,2), padding=\"valid\", kernel_initializer=init)(uconv4)\n",
    "uconv3 = concatenate([deconv3,conv3])\n",
    "uconv3 = Conv2D(f*4, (3,3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "uconv3 = Conv2D(f*4, (3,3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "deconv2 = Conv2DTranspose(f*2, (2,2), padding=\"same\", kernel_initializer=init)(uconv3)\n",
    "uconv2 = concatenate([deconv3,conv3])\n",
    "uconv2 = Conv2D(f*2, (3,3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "uconv2 = Conv2D(f*2, (3,3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "deconv1 = Conv2DTranspose(f, (2,2), padding=\"same\", kernel_initializer=init)(uconv2)\n",
    "uconv1 = concatenate([deconv3,conv3])\n",
    "uconv1 = Conv2D(f, (3,3), activation=\"relu\", padding=\"same\")(deconv1)\n",
    "uconv1 = Conv2D(f, (3,3), activation=\"relu\", padding=\"same\")(deconv1)\n",
    "\n",
    "# output layer \n",
    "outputs = Conv2D(1, (1,1), activation=\"sigmoid\", padding=\"same\")\n",
    "\n",
    "# compile \n",
    "unet = Model(inputs=input_layer, outputs = outputs)\n",
    "unet.compile(optimizer ='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml37",
   "language": "python",
   "name": "ml37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
