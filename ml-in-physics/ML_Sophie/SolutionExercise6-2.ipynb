{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the aim of this exercise is to build a network. In this exercise you should implement the network which is discussed in: [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) (Krizhevsky, Sutskever, Hinton). The network architecture is summarised in Figure 2 of that paper and more detailed descriptions are found in the text.  \n",
    "You only need to implement the architecture and check that your network is consistent. Note, that you can check your results by  \n",
    "a) checking your model is compiling in Keras and  \n",
    "b) by comparing your `model.summary()` with the desired dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel structure of AlexNet is due the fact that it was designed to run on two GPUs. If you don't have access to a GPU, you can use [Google Colab](https://colab.research.google.com). There you can choose to run on a backend with a GPU or TPU. In the Menu, click \"Runtime\" and then \"Change runtime type\".  \n",
    "Unfortunately we only have one GPU available there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simplified version with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 48)   17472       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 48)   17472       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 48)   192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 48)   192         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 56, 56, 48)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 48)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 27, 27, 48)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 48)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 27, 27, 128)  153728      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 27, 27, 128)  153728      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 27, 27, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 27, 27, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 27, 27, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 27, 27, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 13, 13, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 256)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 13, 13, 192)  442560      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 13, 192)  442560      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 192)  331968      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 192)  331968      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 13, 128)  221312      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 128)  221312      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 256)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9216)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         18876416    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         18876416    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4096)         0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         8390656     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         8390656     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4096)         0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4096)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         4097000     flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,966,632\n",
      "Trainable params: 60,965,928\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "# 1st convolution block\n",
    "conv1_up = Conv2D(48, kernel_size=11, strides=4, padding='same')(inputs)\n",
    "batchnorm1_up = BatchNormalization(axis=-1)(conv1_up)\n",
    "act1_up = Activation('relu')(batchnorm1_up)\n",
    "\n",
    "conv1_down = Conv2D(48, kernel_size=11, strides=4, padding='same')(inputs)\n",
    "batchnorm1_down = BatchNormalization(axis=-1)(conv1_down)\n",
    "act1_down = Activation('relu')(batchnorm1_down)\n",
    "\n",
    "maxpool1_up = MaxPooling2D(pool_size=3, strides=2)(act1_up)\n",
    "maxpool1_down = MaxPooling2D(pool_size=3, strides=2)(act1_down)\n",
    "\n",
    "# 2nd convolution block\n",
    "conv2_up = Conv2D(128, kernel_size=5, strides=1, padding='same')(maxpool1_up)\n",
    "batchnorm2_up = BatchNormalization(axis=-1)(conv2_up)\n",
    "act2_up = Activation('relu')(batchnorm2_up)\n",
    "\n",
    "conv2_down = Conv2D(128, kernel_size=5, strides=1, padding='same')(maxpool1_down)\n",
    "batchnorm2_down = BatchNormalization(axis=-1)(conv2_down)\n",
    "act2_down = Activation('relu')(batchnorm2_down)\n",
    "\n",
    "maxpool2_up = MaxPooling2D(pool_size=3, strides=2)(act2_up)\n",
    "maxpool2_down = MaxPooling2D(pool_size=3, strides=2)(act2_down)\n",
    "\n",
    "# 3rd convolution block\n",
    "merge3 = concatenate([maxpool2_up, maxpool2_down])\n",
    "conv3_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "conv3_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "\n",
    "# 4th convolution block\n",
    "conv4_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_up)\n",
    "conv4_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_down)\n",
    "\n",
    "# 5th convolution block\n",
    "conv5_up = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_up)\n",
    "conv5_down = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_down)\n",
    "maxpool5_up = MaxPooling2D(pool_size=3, strides=2)(conv5_up)\n",
    "maxpool5_down = MaxPooling2D(pool_size=3, strides=2)(conv5_down)\n",
    "\n",
    "# Dense Layers 1st block (use dropout)\n",
    "merge_dense1 = concatenate([maxpool5_up, maxpool5_down])\n",
    "flatten_dense1 = Flatten()(merge_dense1)\n",
    "dense1_up = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_up = Dropout(rate=0.5)(dense1_up)\n",
    "dense1_down = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_down = Dropout(rate=0.5)(dense1_down)\n",
    "\n",
    "# Dense Layers 2nd block (use dropout)\n",
    "merge_dense2 = concatenate([dense1_dropout_up, dense1_dropout_down])\n",
    "flatten_dense2 = Flatten()(merge_dense2)\n",
    "dense2_up = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_up = Dropout(rate=0.5)(dense2_up)\n",
    "dense2_down = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_down = Dropout(rate=0.5)(dense2_down)\n",
    "\n",
    "# Softmax\n",
    "merge_dense3 = concatenate([dense2_dropout_up, dense2_dropout_down])\n",
    "flatten_dense3 = Flatten()(merge_dense3)\n",
    "output = Dense(1000, activation='softmax')(flatten_dense3)\n",
    "\n",
    "# Model\n",
    "alex_net = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "alex_net.compile(loss=\"binary_crossentropy\", optimizer='adam')\n",
    "print(alex_net.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output dimension after the first convolution does not match with the one from the paper. I have found several references that state that the $224$ is a typo in the paper and should be $227$. I am not sure if this is true, as the authors quote the number at so many places in the paper. A quick fix that gives the right output dimensions is to change the padding to valid in the first layer and add a symmetric padding of 2. We cannot know for sure what the authors did without their pre-processed data or code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 228, 228, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 228, 228, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 48)   17472       zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 55, 55, 48)   17472       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 48)   192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 48)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 27, 27, 48)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 27, 27, 48)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 27, 27, 128)  153728      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 27, 27, 128)  153728      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 27, 27, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 27, 27, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 27, 27, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 27, 27, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 13, 13, 128)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 13, 13, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 13, 13, 256)  0           max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 13, 13, 192)  442560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 13, 192)  442560      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 192)  331968      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 192)  331968      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, 13, 128)  221312      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 13, 13, 128)  221312      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 6, 6, 128)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 6, 6, 128)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 6, 256)    0           max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 9216)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2048)         18876416    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         18876416    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4096)         0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 4096)         0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         8390656     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2048)         8390656     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2048)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2048)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4096)         0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 4096)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1000)         4097000     flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,966,632\n",
      "Trainable params: 60,965,928\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "# 1st convolution block\n",
    "pad1_up = ZeroPadding2D(2)(inputs) # fix for output dimensions\n",
    "conv1_up = Conv2D(48, kernel_size=11, strides=4, padding='valid')(pad1_up)\n",
    "batchnorm1_up = BatchNormalization(axis=-1)(conv1_up)\n",
    "act1_up = Activation('relu')(batchnorm1_up)\n",
    "\n",
    "pad1_down = ZeroPadding2D(2)(inputs) # fix for output dimensions\n",
    "conv1_down = Conv2D(48, kernel_size=11, strides=4, padding='valid')(pad1_down)\n",
    "batchnorm1_down = BatchNormalization(axis=-1)(conv1_down)\n",
    "act1_down = Activation('relu')(batchnorm1_down)\n",
    "\n",
    "maxpool1_up = MaxPooling2D(pool_size=3, strides=2)(act1_up)\n",
    "maxpool1_down = MaxPooling2D(pool_size=3, strides=2)(act1_down)\n",
    "\n",
    "# 2nd convolution block\n",
    "conv2_up = Conv2D(128, kernel_size=5, strides=1, padding='same')(maxpool1_up)\n",
    "batchnorm2_up = BatchNormalization(axis=-1)(conv2_up)\n",
    "act2_up = Activation('relu')(batchnorm2_up)\n",
    "\n",
    "conv2_down = Conv2D(128, kernel_size=5, strides=1, padding='same')(maxpool1_down)\n",
    "batchnorm2_down = BatchNormalization(axis=-1)(conv2_down)\n",
    "act2_down = Activation('relu')(batchnorm2_down)\n",
    "\n",
    "maxpool2_up = MaxPooling2D(pool_size=3, strides=2)(act2_up)\n",
    "maxpool2_down = MaxPooling2D(pool_size=3, strides=2)(act2_down)\n",
    "\n",
    "# 3rd convolution block\n",
    "merge3 = concatenate([maxpool2_up, maxpool2_down])\n",
    "conv3_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "conv3_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "\n",
    "# 4th convolution block\n",
    "conv4_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_up)\n",
    "conv4_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_down)\n",
    "\n",
    "# 5th convolution block\n",
    "conv5_up = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_up)\n",
    "conv5_down = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_down)\n",
    "maxpool5_up = MaxPooling2D(pool_size=3, strides=2)(conv5_up)\n",
    "maxpool5_down = MaxPooling2D(pool_size=3, strides=2)(conv5_down)\n",
    "\n",
    "# Dense Layers 1st block (use dropout)\n",
    "merge_dense1 = concatenate([maxpool5_up, maxpool5_down])\n",
    "flatten_dense1 = Flatten()(merge_dense1)\n",
    "dense1_up = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_up = Dropout(rate=0.5)(dense1_up)\n",
    "dense1_down = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_down = Dropout(rate=0.5)(dense1_down)\n",
    "\n",
    "# Dense Layers 2nd block (use dropout)\n",
    "merge_dense2 = concatenate([dense1_dropout_up, dense1_dropout_down])\n",
    "flatten_dense2 = Flatten()(merge_dense2)\n",
    "dense2_up = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_up = Dropout(rate=0.5)(dense2_up)\n",
    "dense2_down = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_down = Dropout(rate=0.5)(dense2_down)\n",
    "\n",
    "# Softmax\n",
    "merge_dense3 = concatenate([dense2_dropout_up, dense2_dropout_down])\n",
    "flatten_dense3 = Flatten()(merge_dense3)\n",
    "output = Dense(1000, activation='softmax')(flatten_dense3)\n",
    "\n",
    "# Model\n",
    "alex_net = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "alex_net.compile(loss=\"binary_crossentropy\", optimizer='adam')\n",
    "print(alex_net.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version with Local Response Normalization (LRN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to implement the LRN (see e.g. [here](https://resources.oreilly.com/examples/9781787128422/blob/0e1be827d0179cc535da74957866ed87a4ea0224/DeepLearningwithKeras_Code/Chapter07/tf-keras-func.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Layer, InputSpec\n",
    "\n",
    "class LocalResponseNormalization(Layer):\n",
    "\n",
    "    def __init__(self, n=5, alpha=0.0001, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if K.image_data_format() == \"th\":\n",
    "            _, f, r, c = self.shape\n",
    "        else:\n",
    "            _, r, c, f = self.shape\n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1, 1),\n",
    "        padding=\"same\", pool_mode=\"avg\")\n",
    "        if K.image_data_format() == \"th\":\n",
    "            summed = K.sum(pooled, axis=1, keepdims=True)\n",
    "            averaged = self.alpha * K.repeat_elements(summed, f, axis=1)\n",
    "        else:\n",
    "            summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "            averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CDF64AD908>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CDF64AD908>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD89108C88>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD89108C88>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD891BF348>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD891BF348>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD891B4FC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <bound method LocalResponseNormalization.call of <__main__.LocalResponseNormalization object at 0x000001CD891B4FC8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 228, 228, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 228, 228, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 55, 55, 48)   17472       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 55, 55, 48)   17472       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "local_response_normalization (L (None, 55, 55, 48)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "local_response_normalization_1  (None, 55, 55, 48)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 27, 27, 48)   0           local_response_normalization[0][0\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 27, 27, 48)   0           local_response_normalization_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 27, 27, 128)  153728      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 27, 27, 128)  153728      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "local_response_normalization_2  (None, 27, 27, 128)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "local_response_normalization_3  (None, 27, 27, 128)  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 13, 13, 128)  0           local_response_normalization_2[0]\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 13, 13, 128)  0           local_response_normalization_3[0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 13, 13, 256)  0           max_pooling2d_14[0][0]           \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 13, 13, 192)  442560      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 13, 13, 192)  442560      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 13, 13, 192)  331968      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 13, 192)  331968      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 128)  221312      conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 13, 13, 128)  221312      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 6, 6, 128)    0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 6, 6, 128)    0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 6, 6, 256)    0           max_pooling2d_16[0][0]           \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 9216)         0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2048)         18876416    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2048)         18876416    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2048)         0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 2048)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 4096)         0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 4096)         0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2048)         8390656     flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2048)         8390656     flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 2048)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2048)         0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 4096)         0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 4096)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1000)         4097000     flatten_8[0][0]                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 60,965,224\n",
      "Trainable params: 60,965,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "# 1st convolution block\n",
    "pad1_up = ZeroPadding2D(2)(inputs)\n",
    "conv1_up = Conv2D(48, kernel_size=11, strides=4, padding='valid', activation='relu')(pad1_up)\n",
    "LRN1_up = LocalResponseNormalization()(conv1_up)\n",
    "\n",
    "pad1_down = ZeroPadding2D(2)(inputs)\n",
    "conv1_down = Conv2D(48, kernel_size=11, strides=4, padding='valid', activation='relu')(pad1_down)\n",
    "LRN1_down = LocalResponseNormalization()(conv1_down)\n",
    "\n",
    "maxpool1_up = MaxPooling2D(pool_size=3, strides=2)(LRN1_up)\n",
    "maxpool1_down = MaxPooling2D(pool_size=3, strides=2)(LRN1_down)\n",
    "\n",
    "# 2nd convolution block\n",
    "conv2_up = Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(maxpool1_up)\n",
    "LRN2_up = LocalResponseNormalization()(conv2_up)\n",
    "\n",
    "conv2_down = Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(maxpool1_down)\n",
    "LRN2_down = LocalResponseNormalization()(conv2_down)\n",
    "\n",
    "maxpool2_up = MaxPooling2D(pool_size=3, strides=2)(LRN2_up)\n",
    "maxpool2_down = MaxPooling2D(pool_size=3, strides=2)(LRN2_down)\n",
    "\n",
    "# 3rd convolution block\n",
    "merge3 = concatenate([maxpool2_up, maxpool2_down])\n",
    "conv3_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "conv3_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(merge3)\n",
    "\n",
    "# 4th convolution block\n",
    "conv4_up = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_up)\n",
    "conv4_down = Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(conv3_down)\n",
    "\n",
    "# 5th convolution block\n",
    "conv5_up = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_up)\n",
    "conv5_down = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(conv4_down)\n",
    "maxpool5_up = MaxPooling2D(pool_size=3, strides=2)(conv5_up)\n",
    "maxpool5_down = MaxPooling2D(pool_size=3, strides=2)(conv5_down)\n",
    "\n",
    "# Dense Layers 1st block (use dropout)\n",
    "merge_dense1 = concatenate([maxpool5_up, maxpool5_down])\n",
    "flatten_dense1 = Flatten()(merge_dense1)\n",
    "dense1_up = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_up = Dropout(rate=0.5)(dense1_up)\n",
    "dense1_down = Dense(2048, activation='relu')(flatten_dense1)\n",
    "dense1_dropout_down = Dropout(rate=0.5)(dense1_down)\n",
    "\n",
    "# Dense Layers 2nd block (use dropout)\n",
    "merge_dense2 = concatenate([dense1_dropout_up, dense1_dropout_down])\n",
    "flatten_dense2 = Flatten()(merge_dense2)\n",
    "dense2_up = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_up = Dropout(rate=0.5)(dense2_up)\n",
    "dense2_down = Dense(2048, activation='relu')(flatten_dense2)\n",
    "dense2_dropout_down = Dropout(rate=0.5)(dense2_down)\n",
    "\n",
    "# Softmax\n",
    "merge_dense3 = concatenate([dense2_dropout_up, dense2_dropout_down])\n",
    "flatten_dense3 = Flatten()(merge_dense3)\n",
    "output = Dense(1000, activation='softmax')(flatten_dense3)\n",
    "\n",
    "# Model\n",
    "alex_net = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "alex_net.compile(loss=\"binary_crossentropy\", optimizer='adam')\n",
    "print(alex_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.backend' has no attribute 'get_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7cc1dc94a5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# write to files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtb_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"logs_alexnet/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.backend' has no attribute 'get_session'"
     ]
    }
   ],
   "source": [
    "# get graph\n",
    "graph = K.get_session().graph\n",
    "\n",
    "# write to files\n",
    "tb_path = \"logs_alexnet/\"\n",
    "writer = tf.summary.FileWriter(logdir=tb_path, graph=graph)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tensorboard in shell -> interrupt kernel to stop\n",
    "# you can click the link to see the graph of the network we built\n",
    "!tensorboard --logdir=logs_alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above link does not work for some reason, you should find tensorboard at [localhost:6006](http://localhost:6006)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml37",
   "language": "python",
   "name": "ml37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
