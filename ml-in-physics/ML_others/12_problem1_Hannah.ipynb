{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b263c990",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7321ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Hannah Lange\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb41f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-communist",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4ea1c74088e49216c43b1b71dd50f46",
     "grade": false,
     "grade_id": "cell-9635ca01b4f315fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-grove",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "748169043d52b8f34628c6a206255935",
     "grade": false,
     "grade_id": "cell-98d9aa4804750ac3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# GridWorld\n",
    "\n",
    "We have two classes: one for the environment `GridWorld` and one for the agent `Agent`, which follows the Q-learning policy. The dimensions of the grid are 5x5, we have one pitfall at (1,3) and the exit is at (0,3). The Agent wins when it finds the exit (reward +10) and loses when it hits the pitfall (reward -10), in both cases the episode is terminated. Each step is punished by a negative reward of -1. Possible actions are UP, DOWN, RIGHT, LEFT. The gird stores all the rewards as given in the `__init__()`.\n",
    "\n",
    "* Complete the `make_step` method in the `GridWorld` class, that moves the agent in a specified direction. If agent is at a border, agent stays still but takes negative reward.\n",
    "\n",
    "* Write the functions `chose_action` and `learn` in the `Agent` class. Follow the instructions to implement Q-learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-american",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4888bbb18f8919deb6836d14e2a874ab",
     "grade": false,
     "grade_id": "cell-76884f9962d0298a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    ## Initialise starting data\n",
    "    def __init__(self, exit_reward=10, pitfall_reward=-10, step_reward=-1):\n",
    "        # Set information about the gridworld\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "               \n",
    "        \n",
    "        # Set random start location for the agent\n",
    "        self.current_location = ( 4, np.random.randint(0,5))\n",
    "        \n",
    "        # Set locations for the bomb and the gold\n",
    "        self.pitfall_location = (1,3)\n",
    "        self.exit_location = (0,3)\n",
    "        self.terminal_states = [ self.pitfall_location, self.exit_location]\n",
    "        \n",
    "        # Set grid rewards for cells\n",
    "        self.grid = np.zeros(( self.height, self.width)) + step_reward # reward of -1 is given per step\n",
    "        self.grid[ self.pitfall_location[0], self.pitfall_location[1]] = pitfall_reward\n",
    "        self.grid[ self.exit_location[0], self.exit_location[1]] = exit_reward\n",
    "        # Set available actions\n",
    "        self.actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"resets the position of the agent to the bottom of the grid\"\"\"\n",
    "        self.current_location = ( 4, np.random.randint(0,5))\n",
    "        \n",
    "    def get_available_actions(self):\n",
    "        \"\"\"Returns possible actions\"\"\"\n",
    "        return self.actions\n",
    "    \n",
    "    def agent_on_map(self):\n",
    "        \"\"\"Prints out current location of the agent on the grid (used for debugging)\"\"\"\n",
    "        grid = np.zeros(( self.height, self.width))\n",
    "        grid[ self.current_location[0], self.current_location[1]] = 1\n",
    "        return grid\n",
    "    \n",
    "    def get_reward(self, new_location):\n",
    "        \"\"\"Returns the reward for an input position\"\"\"\n",
    "        return self.grid[ new_location[0], new_location[1]]\n",
    "        \n",
    "    \n",
    "    def make_step(self, action):\n",
    "        \"\"\"Moves the agent in the specified direction. If agent is at a border, agent stays still\n",
    "        but takes negative reward. Function returns the reward for the move. Make sure to update\n",
    "        the current location.\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        #print(self.current_location)\n",
    "        if action == \"UP\":\n",
    "            new_location = (self.current_location[0] - 1, self.current_location[1])\n",
    "        elif action == \"DOWN\":\n",
    "            new_location = (self.current_location[0] + 1, self.current_location[1])\n",
    "        elif action == \"LEFT\":\n",
    "            new_location = (self.current_location[0], self.current_location[1] - 1)\n",
    "        elif action == \"RIGHT\":\n",
    "            new_location = (self.current_location[0], self.current_location[1] + 1)\n",
    "        else:\n",
    "            print(\"Choose one of UP, DOWN, LEFT, RIGHT\")\n",
    "            new_location = self.current_location\n",
    "        if new_location[0] >= self.width or new_location[0] < 0:\n",
    "            new_location = self.current_location\n",
    "        if new_location[1] >= self.height or new_location[1] < 0:\n",
    "            new_location = self.current_location\n",
    "        reward = self.get_reward(new_location)\n",
    "        self.current_location = new_location\n",
    "        #print(self.current_location)\n",
    "        return reward\n",
    "    \n",
    "    def check_state(self):\n",
    "        \"\"\"Check if the agent is in a terminal state (exit or pitfall), if so return 'TERMINAL'\"\"\"\n",
    "        if self.current_location in self.terminal_states:\n",
    "            return 'TERMINAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corporate-buffer",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08cfe6ea0101de8c199fff507311d076",
     "grade": true,
     "grade_id": "cell-7e07401611390624",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cross-notebook",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9823c977329dc36932fb92cc4b5f141",
     "grade": true,
     "grade_id": "cell-df82fda1d418540d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testenv = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "testenv.current_location=(0,0)\n",
    "assert testenv.make_step('UP') == -1\n",
    "assert testenv.make_step('RIGHT') == -1\n",
    "assert testenv.make_step('LEFT') == -1\n",
    "assert testenv.make_step('DOWN') == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exempt-riverside",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2042a7b31a244288d2e645d50afc8d18",
     "grade": true,
     "grade_id": "cell-3cacc812d1748c81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testenv = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "testenv.current_location=testenv.pitfall_location\n",
    "assert testenv.make_step('UP') == 10\n",
    "assert testenv.make_step('DOWN') == -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "juvenile-patch",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee43ece65d00b532d9cd4630690ee428",
     "grade": false,
     "grade_id": "cell-344b10e065d6b030",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Agent that runs on the Q-learning algorithm\"\"\"\n",
    "   \n",
    "    def __init__(self, environment, epsilon=0.05, alpha=0.1, gamma=1):\n",
    "        \"\"\" alpha: learning rate\n",
    "            gamma: discount factor\n",
    "            epsilon: exploration rate\n",
    "        \"\"\"\n",
    "        \n",
    "        self.environment = environment\n",
    "        self.q_table = dict() # Store all Q-values in dictionary of dictionaries \n",
    "        for x in range(environment.height): # Loop through all possible grid spaces, create sub-dictionary for each\n",
    "            for y in range(environment.width):\n",
    "                self.q_table[(x,y)] = {'UP':0, 'DOWN':0, 'LEFT':0, 'RIGHT':0} # Populate sub-dictionary with zero values for possible moves\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\"Returns the next action the agent should take.\n",
    "        Will make an exploratory random action dependent on epsilon (epsilon-greedy) otherwise will \n",
    "        choose the optimal action from the q-value table. The optimal action is the one with the\n",
    "        maximum Q-Value.\n",
    "        If there are multiple optimal actions, chooses the action randomly from optimal actions. \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        possible_actions = self.environment.actions\n",
    "        p = np.random.random()\n",
    "        if p <= self.epsilon:\n",
    "            action = np.random.choice(possible_actions)\n",
    "        else:\n",
    "            q_table_values = np.array(list(self.q_table[self.environment.current_location].values()))\n",
    "            index = np.where(max(q_table_values) == q_table_values)[0]\n",
    "            if len(index) > 1:\n",
    "                choices = []\n",
    "                for i in index:\n",
    "                    choices.append(list(self.q_table[self.environment.current_location].keys())[i])\n",
    "                action = np.random.choice(choices)\n",
    "            else:\n",
    "                action = list(self.q_table[self.environment.current_location].keys())[index[0]]\n",
    "        return action\n",
    "    \n",
    "    def learn(self, old_state, reward, new_state, action):\n",
    "        \"\"\"Updates the Q-value table value self.q_table[old_state][action] by:\n",
    "        Q(s, a) = Q(s, a) + alpha*(R + gamma * max_a'(Q(s', a')) - Q(s, a))\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        qs = [self.q_table[new_state][a] for a in self.environment.actions]\n",
    "        q_old = self.q_table[old_state][action]\n",
    "        self.q_table[old_state][action] = q_old + self.alpha * (reward + self.gamma * (max(qs) - q_old))\n",
    "        \n",
    "        \n",
    "    def play(self, trials=500, max_steps_per_episode=1000):\n",
    "        \"\"\"The play function runs iterations and updates Q-values if desired.\"\"\"\n",
    "        reward_per_episode = [] # Initialise performance log\n",
    "\n",
    "        for trial in range(trials): # Run trials\n",
    "            cumulative_reward = 0 # Initialise values of each game\n",
    "            step = 0\n",
    "            game_over = False\n",
    "            while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
    "                old_state = self.environment.current_location\n",
    "                action = self.choose_action() \n",
    "                reward = self.environment.make_step(action)\n",
    "                new_state = self.environment.current_location\n",
    "\n",
    "                # Update Q-values \n",
    "                self.learn(old_state, reward, new_state, action)\n",
    "\n",
    "                cumulative_reward += reward\n",
    "                step += 1\n",
    "\n",
    "                if self.environment.check_state() == 'TERMINAL': # If game is in terminal state, game over and start next trial\n",
    "                    self.environment.reset()\n",
    "                    game_over = True     \n",
    "\n",
    "            reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log\n",
    "\n",
    "        return reward_per_episode # Return performance log\n",
    "    \n",
    "    \n",
    "    def print_q_table(self):\n",
    "        pprint(dict(self.q_table))\n",
    "        \n",
    "    def plot_environment(self):\n",
    "        policy = []\n",
    "        for pos in self.q_table.values(): \n",
    "            if max(pos.values()) == min(pos.values()):\n",
    "                policy.append(None)\n",
    "            else:                 \n",
    "                policy.append(max(pos, key=pos.get))            \n",
    "        policy = np.asarray(policy).reshape((5,5))\n",
    "        #plt.figure()\n",
    "        #ax = sns.heatmap(policy, annot=True)\n",
    "        #ax.invert_yaxis()\n",
    "        #ax.set_ylim(-0.1, 3.1)\n",
    "        #plt.show()\n",
    "        print(policy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cosmetic-swimming",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e5a2a7a8683200e866376a15190db5",
     "grade": true,
     "grade_id": "cell-840f39dbbbd9c1c5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuing-outdoors",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5529385b12ba76925af3d6ed279f0e1",
     "grade": true,
     "grade_id": "test_q_learning",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "phantom-frequency",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79de5c66f1ecba373d4afb6b9c17e223",
     "grade": true,
     "grade_id": "cell-4c10c4294f385805",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neutral-symbol",
   "metadata": {},
   "source": [
    "\n",
    "## Agent\n",
    "\n",
    "*    Play around with the Agent, what happens for different rewards and parameters $\\alpha$, $\\epsilon$ and $\\gamma$\n",
    "*    Plot the performance and the q_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressed-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['UP' 'RIGHT' 'RIGHT' None 'LEFT']\n",
      " ['LEFT' 'RIGHT' 'UP' None 'UP']\n",
      " ['LEFT' 'RIGHT' 'UP' 'LEFT' 'UP']\n",
      " ['RIGHT' 'RIGHT' 'UP' 'LEFT' 'LEFT']\n",
      " ['RIGHT' 'UP' 'UP' 'UP' 'UP']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "agentQ = Agent(environment)\n",
    "\n",
    "# Note the learn=True argument!\n",
    "reward_per_episode = agentQ.play(trials=500,max_steps_per_episode=500)\n",
    "\n",
    "# Simple learning curve\n",
    "plt.plot(reward_per_episode)\n",
    "agentQ.plot_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "departmental-tobago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "injured-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-c4f24b27",
   "language": "python",
   "display_name": "PyCharm (MLinPhysics)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}