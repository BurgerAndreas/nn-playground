{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b263c990",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7321ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Simon Mathias Linsel\"\n",
    "COLLABORATORS = \"Marcus Culemann, Andreas Burger, Hannah Lange\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb41f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-communist",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4ea1c74088e49216c43b1b71dd50f46",
     "grade": false,
     "grade_id": "cell-9635ca01b4f315fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-grove",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "748169043d52b8f34628c6a206255935",
     "grade": false,
     "grade_id": "cell-98d9aa4804750ac3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# GridWorld\n",
    "\n",
    "We have two classes: one for the environment `GridWorld` and one for the agent `Agent`, which follows the Q-learning policy. The dimensions of the grid are 5x5, we have one pitfall at (1,3) and the exit is at (0,3). The Agent wins when it finds the exit (reward +10) and loses when it hits the pitfall (reward -10), in both cases the episode is terminated. Each step is punished by a negative reward of -1. Possible actions are UP, DOWN, RIGHT, LEFT. The gird stores all the rewards as given in the `__init__()`.\n",
    "\n",
    "* Complete the `make_step` method in the `GridWorld` class, that moves the agent in a specified direction. If agent is at a border, agent stays still but takes negative reward.\n",
    "\n",
    "* Write the functions `chose_action` and `learn` in the `Agent` class. Follow the instructions to implement Q-learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "endangered-american",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4888bbb18f8919deb6836d14e2a874ab",
     "grade": false,
     "grade_id": "cell-76884f9962d0298a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    ## Initialise starting data\n",
    "    def __init__(self, exit_reward=10, pitfall_reward=-10, step_reward=-1):\n",
    "        # Set information about the gridworld\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "               \n",
    "        \n",
    "        # Set random start location for the agent\n",
    "        self.current_location = ( 4, np.random.randint(0,5))\n",
    "        \n",
    "        # Set locations for the bomb and the gold\n",
    "        self.pitfall_location = (1,3)\n",
    "        self.exit_location = (0,3)\n",
    "        self.terminal_states = [ self.pitfall_location, self.exit_location]\n",
    "        \n",
    "        # Set grid rewards for cells\n",
    "        self.grid = np.zeros(( self.height, self.width)) + step_reward # reward of -1 is given per step\n",
    "        self.grid[ self.pitfall_location[0], self.pitfall_location[1]] = pitfall_reward\n",
    "        self.grid[ self.exit_location[0], self.exit_location[1]] = exit_reward\n",
    "        \n",
    "        # Set available actions\n",
    "        self.actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"resets the position of the agent to the bottom of the grid\"\"\"\n",
    "        self.current_location = ( 4, np.random.randint(0,5))\n",
    "        \n",
    "    def get_available_actions(self):\n",
    "        \"\"\"Returns possible actions\"\"\"\n",
    "        return self.actions\n",
    "    \n",
    "    def agent_on_map(self):\n",
    "        \"\"\"Prints out current location of the agent on the grid (used for debugging)\"\"\"\n",
    "        grid = np.zeros(( self.height, self.width))\n",
    "        grid[ self.current_location[0], self.current_location[1]] = 1\n",
    "        return grid\n",
    "    \n",
    "    def get_reward(self, new_location):\n",
    "        \"\"\"Returns the reward for an input position\"\"\"\n",
    "        return self.grid[ new_location[0], new_location[1]]\n",
    "        \n",
    "    \n",
    "    def make_step(self, action):\n",
    "        \"\"\"Moves the agent in the specified direction. If agent is at a border, agent stays still\n",
    "        but takes negative reward. Function returns the reward for the move. Make sure to update\n",
    "        the current location.\"\"\"\n",
    "        \n",
    "        if action == 'UP':\n",
    "            next_state = (self.current_location[0] - 1, self.current_location[1])\n",
    "        elif action == 'DOWN':\n",
    "            next_state = (self.current_location[0] + 1, self.current_location[1])\n",
    "        elif action == 'LEFT':\n",
    "            next_state = (self.current_location[0], self.current_location[1] - 1)\n",
    "        elif action == 'RIGHT':\n",
    "            next_state = (self.current_location[0], self.current_location[1] + 1)\n",
    "            \n",
    "        if next_state[0] >= 0 and next_state[0] < self.height:\n",
    "            if next_state[1] >= 0 and next_state[1] < self.width:\n",
    "                self.current_location = next_state\n",
    "        reward = self.get_reward(self.current_location)\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def check_state(self):\n",
    "        \"\"\"Check if the agent is in a terminal state (exit or pitfall), if so return 'TERMINAL'\"\"\"\n",
    "        if self.current_location in self.terminal_states:\n",
    "            return 'TERMINAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-buffer",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08cfe6ea0101de8c199fff507311d076",
     "grade": true,
     "grade_id": "cell-7e07401611390624",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cross-notebook",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9823c977329dc36932fb92cc4b5f141",
     "grade": true,
     "grade_id": "cell-df82fda1d418540d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testenv = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "testenv.current_location=(0,0)\n",
    "assert testenv.make_step('UP') == -1\n",
    "assert testenv.make_step('RIGHT') == -1\n",
    "assert testenv.make_step('LEFT') == -1\n",
    "assert testenv.make_step('DOWN') == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "exempt-riverside",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2042a7b31a244288d2e645d50afc8d18",
     "grade": true,
     "grade_id": "cell-3cacc812d1748c81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testenv = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "testenv.current_location=testenv.pitfall_location\n",
    "assert testenv.make_step('UP') == 10\n",
    "assert testenv.make_step('DOWN') == -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "juvenile-patch",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee43ece65d00b532d9cd4630690ee428",
     "grade": false,
     "grade_id": "cell-344b10e065d6b030",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Agent that runs on the Q-learning algorithm\"\"\"\n",
    "   \n",
    "    def __init__(self, environment, epsilon=0.05, alpha=0.1, gamma=1):\n",
    "        \"\"\" alpha: learning rate\n",
    "            gamma: discount factor\n",
    "            epsilon: exploration rate\n",
    "        \"\"\"\n",
    "        \n",
    "        self.environment = environment\n",
    "        self.q_table = dict() # Store all Q-values in dictionary of dictionaries \n",
    "        for x in range(environment.height): # Loop through all possible grid spaces, create sub-dictionary for each\n",
    "            for y in range(environment.width):\n",
    "                self.q_table[(x,y)] = {'UP':0, 'DOWN':0, 'LEFT':0, 'RIGHT':0} # Populate sub-dictionary with zero values for possible moves\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\"Returns the next action the agent should take.\n",
    "        Will make an exploratory random action dependent on epsilon (epsilon-greedy) otherwise will \n",
    "        choose the optimal action from the q-value table. The optimal action is the one with the\n",
    "        maximum Q-Value.\n",
    "        If there are multiple optimal actions, chooses the action randomly from optimal actions. \"\"\"\n",
    "        \n",
    "        # choose action with most expected value\n",
    "        maximum_q = None\n",
    "        possible_actions = []\n",
    "        \n",
    "        # with probability epsilon, choose random action\n",
    "        if np.random.uniform(0, 1) <= self.epsilon:\n",
    "            action = np.random.choice(self.environment.actions)\n",
    "        else:\n",
    "            # greedy action\n",
    "            for a in self.environment.actions:\n",
    "                q = self.q_table[self.environment.current_location][a]  \n",
    "                if maximum_q == None:\n",
    "                    maximum_q = q\n",
    "                    possible_actions = [a]\n",
    "                elif q == maximum_q:\n",
    "                    possible_actions.append(a)\n",
    "                elif q > maximum_q:\n",
    "                    possible_actions = [a]\n",
    "                    maximum_q = q\n",
    "            \n",
    "            action = np.random.choice(possible_actions)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def learn(self, old_state, reward, new_state, action):\n",
    "        \"\"\"Updates the Q-value table value self.q_table[old_state][action] by:\n",
    "        Q(s, a) = Q(s, a) + alpha*(R + gamma * max_a'(Q(s', a')) - Q(s, a))\"\"\"\n",
    "        \n",
    "        maximum_q = None\n",
    "        q_list = []\n",
    "        \n",
    "        for a in self.environment.actions:\n",
    "            q = self.q_table[new_state][a]  \n",
    "            q_list.append(q)    \n",
    "        maximum_q = np.max(q_list)\n",
    "        \n",
    "        self.q_table[old_state][action] = self.q_table[old_state][action] + self.alpha * (reward + self.gamma * (maximum_q - self.q_table[old_state][action]) )\n",
    "        \n",
    "        \n",
    "    def play(self, trials=500, max_steps_per_episode=1000):\n",
    "        \"\"\"The play function runs iterations and updates Q-values if desired.\"\"\"\n",
    "        reward_per_episode = [] # Initialise performance log\n",
    "\n",
    "        for trial in range(trials): # Run trials\n",
    "            cumulative_reward = 0 # Initialise values of each game\n",
    "            step = 0\n",
    "            game_over = False\n",
    "            while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
    "                old_state = self.environment.current_location\n",
    "                action = self.choose_action() \n",
    "                reward = self.environment.make_step(action)\n",
    "                new_state = self.environment.current_location\n",
    "\n",
    "                # Update Q-values \n",
    "                self.learn(old_state, reward, new_state, action)\n",
    "\n",
    "                cumulative_reward += reward\n",
    "                step += 1\n",
    "\n",
    "                if self.environment.check_state() == 'TERMINAL': # If game is in terminal state, game over and start next trial\n",
    "                    self.environment.reset()\n",
    "                    game_over = True     \n",
    "\n",
    "            reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log\n",
    "\n",
    "        return reward_per_episode # Return performance log\n",
    "    \n",
    "    \n",
    "    def print_q_table(self):\n",
    "        pprint(dict(self.q_table))\n",
    "        \n",
    "    def plot_environment(self):\n",
    "        policy = []\n",
    "        for pos in self.q_table.values(): \n",
    "            if max(pos.values()) == min(pos.values()):\n",
    "                policy.append(None)\n",
    "            else:                 \n",
    "                policy.append(max(pos, key=pos.get))            \n",
    "        policy = np.asarray(policy).reshape((5,5))\n",
    "        #plt.figure()\n",
    "        #ax = sns.heatmap(policy, annot=True)\n",
    "        #ax.invert_yaxis()\n",
    "        #ax.set_ylim(-0.1, 3.1)\n",
    "        #plt.show()\n",
    "        print(policy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-swimming",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e5a2a7a8683200e866376a15190db5",
     "grade": true,
     "grade_id": "cell-840f39dbbbd9c1c5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-outdoors",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5529385b12ba76925af3d6ed279f0e1",
     "grade": true,
     "grade_id": "test_q_learning",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-frequency",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79de5c66f1ecba373d4afb6b9c17e223",
     "grade": true,
     "grade_id": "cell-4c10c4294f385805",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neutral-symbol",
   "metadata": {},
   "source": [
    "\n",
    "## Agent\n",
    "\n",
    "*    Play around with the Agent, what happens for different rewards and parameters $\\alpha$, $\\epsilon$ and $\\gamma$\n",
    "*    Plot the performance and the q_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pressed-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['RIGHT' 'RIGHT' 'RIGHT' None 'LEFT']\n",
      " ['DOWN' 'UP' 'UP' None 'UP']\n",
      " ['RIGHT' 'RIGHT' 'UP' 'LEFT' 'UP']\n",
      " ['RIGHT' 'RIGHT' 'UP' 'LEFT' 'LEFT']\n",
      " ['UP' 'RIGHT' 'UP' 'UP' 'UP']]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = GridWorld(exit_reward=10, pitfall_reward=-10, step_reward=-1)\n",
    "agentQ = Agent(environment)\n",
    "\n",
    "# Note the learn=True argument!\n",
    "reward_per_episode = agentQ.play(trials=500,max_steps_per_episode=500)\n",
    "\n",
    "# Simple learning curve\n",
    "plt.plot(reward_per_episode)\n",
    "agentQ.plot_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-tobago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b66fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
